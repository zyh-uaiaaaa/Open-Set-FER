{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc35c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from resnet import *\n",
    "\n",
    "\n",
    "test_num = 0 ##### open class number\n",
    "\n",
    "\n",
    "class RafDataset(data.Dataset):\n",
    "    def __init__(self, args, phase, basic_aug=True, transform=None):\n",
    "        self.raf_path = args.raf_path\n",
    "        self.phase = phase\n",
    "        self.basic_aug = basic_aug\n",
    "        self.transform = transform\n",
    "        df = pd.read_csv(args.label_path, sep=' ', header=None)\n",
    "\n",
    "        name_c = 0\n",
    "        label_c = 1\n",
    "        if phase == 'train':\n",
    "            dataset = df[df[name_c].str.startswith('train')]\n",
    "        else:\n",
    "            dataset = df[df[name_c].str.startswith('test')]\n",
    "\n",
    "        \n",
    "        \n",
    "        self.label = dataset.iloc[:, label_c].values - 1\n",
    "        images_names = dataset.iloc[:, name_c].values\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        self.aug_func = [flip_image, add_g]\n",
    "        self.file_paths = []\n",
    "\n",
    "        for f in images_names:\n",
    "            f = f.split(\".\")[0]\n",
    "            f += '_aligned.jpg'\n",
    "            file_name = os.path.join(self.raf_path, 'Image/aligned', f)\n",
    "            self.file_paths.append(file_name)\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label[idx]\n",
    "        image = cv2.imread(self.file_paths[idx])\n",
    "        image = image[:, :, ::-1]\n",
    "\n",
    "        if self.phase == 'train':\n",
    "\n",
    "            if self.basic_aug and random.uniform(0, 1) > 0.5:\n",
    "                index = random.randint(0, 1)\n",
    "                image = self.aug_func[index](image)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "\n",
    "        return image, label, idx\n",
    "    \n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class res18feature(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=6, drop_rate=0.4, out_dim=64):\n",
    "        super(res18feature, self).__init__()\n",
    "        #'affectnet_baseline/resnet18_msceleb.pth'\n",
    "        res18 = ResNet(block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000)\n",
    "        \n",
    "        msceleb_model = torch.load('./checkpoint/resnet18_msceleb.pth')\n",
    "        state_dict = msceleb_model['state_dict']\n",
    "        res18.load_state_dict(state_dict, strict=False)\n",
    "        self.out_dim = out_dim\n",
    "        self.features = nn.Sequential(*list(res18.children())[:-2])\n",
    "        self.features2 = nn.Sequential(*list(res18.children())[-2:-1])\n",
    "        self.fc = nn.Linear(args.out_dimension, 6)\n",
    "        \n",
    "        self.parm={}\n",
    "        for name,parameters in self.fc.named_parameters():\n",
    "            self.parm[name]=parameters\n",
    "            \n",
    "    def forward(self, x, target, phase='train'):\n",
    "        x = self.features(x)        \n",
    "        x = self.features2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--raf_path', type=str, default='../data/raf-basic',help='raf_dataset_path')\n",
    "parser.add_argument('--pretrained_backbone_path', type=str, default='../checkpoint/resnet18_msceleb.pth', help='pretrained_backbone_path')\n",
    "parser.add_argument('--label_path', type=str, default='../data/raf-basic/EmoLabel/list_patition_label.txt', help='label_path')\n",
    "parser.add_argument('--workers', type=int, default=8, help='number of workers')\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='batch_size')\n",
    "parser.add_argument('--epochs', type=int, default=60, help='number of epochs')\n",
    "parser.add_argument('--out_dimension', type=int, default=512, help='feature dimension')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "setup_seed(0)\n",
    "res18 = res18feature(args)\n",
    "\n",
    "        \n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]) ])\n",
    "\n",
    "data_transforms_val = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]) ])\n",
    "\n",
    "train_dataset = RafDataset(args, phase='train', transform=data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.workers,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "res18.cuda()\n",
    "res18 = torch.nn.DataParallel(res18)\n",
    "\n",
    "params = res18.parameters()\n",
    "res18.module.load_state_dict(torch.load('0.pth')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35acd786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end...\n"
     ]
    }
   ],
   "source": [
    "class TESTRAF(data.Dataset):\n",
    "    def __init__(self, args, phase, basic_aug=True, transform=None):\n",
    "        self.raf_path = args.raf_path\n",
    "        self.phase = phase\n",
    "        self.basic_aug = basic_aug\n",
    "        self.transform = transform\n",
    "        df = pd.read_csv(args.label_path, sep=' ', header=None)\n",
    "        name_c = 0\n",
    "        label_c = 1\n",
    "\n",
    "        dataset = df[df[name_c].str.startswith('test')]\n",
    "        \n",
    "        \n",
    "        self.label = dataset.iloc[:, label_c].values - 1\n",
    "        images_names = dataset.iloc[:, name_c].values\n",
    "                \n",
    "\n",
    "        self.aug_func = [flip_image, add_g]\n",
    "        self.file_paths = []\n",
    "\n",
    "        for f in images_names:\n",
    "            f = f.split(\".\")[0]\n",
    "            f += '_aligned.jpg'\n",
    "            file_name = os.path.join(self.raf_path, 'Image/aligned', f)\n",
    "            self.file_paths.append(file_name)\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label[idx]\n",
    "        image = cv2.imread(self.file_paths[idx])\n",
    "        image = image[:, :, ::-1]\n",
    "        image = self.transform(image)\n",
    "        return image, label, idx\n",
    "    \n",
    "data_transforms_val = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]) ])\n",
    "\n",
    "test_dataset = TESTRAF(args, phase='test', transform=data_transforms_val)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)   \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    res18.eval()\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "    data_num = 0\n",
    "    total = []\n",
    "    for batch_i, (imgs, labels, indexes) in enumerate(test_loader):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        output = res18(imgs, labels, phase='test')\n",
    "\n",
    "        total.append(output.cpu().numpy())\n",
    "    print('end...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a848583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3068\n"
     ]
    }
   ],
   "source": [
    "new_total = np.concatenate(total)\n",
    "test_score = new_total.max(axis=-1)\n",
    "print(len(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56835dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_idx = []\n",
    "ind_idx = []\n",
    "for i in range(test_loader.dataset.__len__()):\n",
    "    if test_loader.dataset.label[i] == test_num:\n",
    "        open_idx.append(i)\n",
    "    else:\n",
    "        ind_idx.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2484d",
   "metadata": {},
   "source": [
    "## construct open-set using open-set samples from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c388028f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end...\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    res18.eval()\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "    data_num = 0\n",
    "    train_open = []\n",
    "    for batch_i, (imgs, labels, indexes) in enumerate(train_loader):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        output = res18(imgs, labels, phase='test')\n",
    "        train_open.append(output.cpu().numpy())\n",
    "    print('end...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5732f",
   "metadata": {},
   "source": [
    "## find samples of open class (test_num) from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f72bc97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619\n"
     ]
    }
   ],
   "source": [
    "new_train_open = np.concatenate(train_open)\n",
    "train_score = new_train_open.max(axis=-1)\n",
    "train_open_idx = []\n",
    "for i in range(train_loader.dataset.__len__()):\n",
    "    if train_loader.dataset.label[i] == test_num:\n",
    "        train_open_idx.append(i)\n",
    "total_open_scores = np.concatenate((test_score[np.array(open_idx)], train_score[np.array(train_open_idx)]))\n",
    "print(len(total_open_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469564c",
   "metadata": {},
   "source": [
    "## the distribution of close-set (closed class samples from test-set) and open-set (open class samples from both train-set and test-set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53628cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(test_score[np.array(ind_idx)], bins=100, alpha=0.5, color='green', label='known') \n",
    "plt.hist(total_open_scores, bins=100, alpha=0.5, color='red', label='open set(surprise)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3469a8",
   "metadata": {},
   "source": [
    "## open-set detection performance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1562dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9129092032118592\n",
      "0.43684198301431904\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "from ood_metrics import fpr_at_95_tpr\n",
    "from ood_metrics import auroc\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X1 = test_score[np.array(ind_idx)]\n",
    "Y1 = total_open_scores\n",
    "\n",
    "labels = np.concatenate((np.ones(len(X1)), np.zeros(len(Y1))))\n",
    "scores = np.concatenate((X1, Y1))\n",
    "fprBase = fpr_at_95_tpr(scores, labels)\n",
    "aurocBase = auroc(scores, labels)\n",
    "print(fprBase)\n",
    "print(aurocBase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1abefb",
   "metadata": {},
   "source": [
    "## generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d40fdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predicts = np.concatenate((new_total, new_train_open[np.array(train_open_idx)]))\n",
    "predicted_labels = np.argmax(total_predicts, axis=1)\n",
    "total_image_paths = np.concatenate((test_loader.dataset.file_paths, np.array(train_loader.dataset.file_paths)[np.array(train_open_idx)]))\n",
    "total_labels = np.concatenate((test_loader.dataset.label, np.array(train_loader.dataset.label)[np.array(train_open_idx)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9087d",
   "metadata": {},
   "source": [
    "## predict pseudo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e76dd44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = open('predicted_labels_open'+str(test_num)+'.txt',\"w+\")\n",
    "for i in range(len(predicted_labels)):\n",
    "    new_file.write(total_image_paths[i] + ' ' + str(predicted_labels[i]) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a1cb5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_idx = []\n",
    "ind_idx = []\n",
    "for i in range(len(total_labels)):\n",
    "    if total_labels[i] == test_num:\n",
    "        open_idx.append(i)\n",
    "    else:\n",
    "        ind_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fc44f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619\n"
     ]
    }
   ],
   "source": [
    "print(len(open_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "162ff253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2739\n"
     ]
    }
   ],
   "source": [
    "print(len(ind_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1eb4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predicted_labels_open'+str(test_num)+'_openset_index.txt', 'w+') as f:\n",
    "    for i in range(len(open_idx)):\n",
    "        f.write(str(open_idx[i]) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48594b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
